{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29de0417",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e774a8d4",
   "metadata": {},
   "source": [
    "Modelos de Linguagem Grande (LLMs, na sigla em ingl√™s) s√£o um componente central do LangChain. O LangChain n√£o fornece seus pr√≥prios LLMs, mas sim oferece uma interface padr√£o para interagir com diversos LLMs diferentes. Para ser espec√≠fico, essa interface √© uma que recebe como entrada uma string e retorna uma string.\n",
    "\n",
    "Existem muitos provedores de LLMs (OpenAI, Cohere, Hugging Face, etc) - a classe LLM √© projetada para fornecer uma interface padr√£o para todos eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925e5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d501a6ce",
   "metadata": {},
   "source": [
    "### Chamando a llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6ecc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez um jovem curioso e sempre em busca de novos desafios. Ele sempre se interessou por tecnologia e desde cedo sonhava em criar seus pr√≥prios jogos e aplicativos. Por√©m, n√£o sabia por onde come√ßar.\n",
      "\n",
      "Um dia, esse jovem ouviu falar sobre programa√ß√£o e como ela era a base de tudo que ele admirava no mundo da tecnologia. Decidiu ent√£o embarcar em uma jornada de aprendizado.\n",
      "\n",
      "No come√ßo, tudo parecia muito complicado e confuso. Ele n√£o entendia nada de c√≥digos e ficava frustrado por n√£o conseguir realizar suas ideias. Mas com determina√ß√£o e muita paci√™ncia, ele come√ßou a estudar e praticar diariamente.\n",
      "\n",
      "Ao longo dos meses, o jovem foi se aperfei√ßoando e entendendo melhor os conceitos da programa√ß√£o. Ele descobriu que n√£o se tratava apenas de escrever linhas de c√≥digos, mas sim de resolver problemas e criar solu√ß√µes.\n",
      "\n",
      "Com o tempo, ele foi se envolvendo em projetos e desafios cada vez mais complexos e seu conhecimento foi crescendo exponencial\n"
     ]
    }
   ],
   "source": [
    "pergunta = 'Conte uma hist√≥ria breve sobre a jornada de aprender a programar'\n",
    "resposta = llm.invoke(pergunta)\n",
    "print(resposta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ade95d2",
   "metadata": {},
   "source": [
    "### Chamando com stream de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922a0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez uma jovem chamada Sofia que sempre foi fascinada por tecnologia e computadores. Desde crian√ßa, ela passava horas navegando na internet e jogando jogos online. Mas um dia, ela percebeu que queria fazer mais do que apenas usar as tecnologias criadas por outras pessoas, ela queria ser capaz de criar suas pr√≥prias aplica√ß√µes e programas.\n",
      "\n",
      "Decidida a aprender a programar, Sofia se matriculou em um curso b√°sico de programa√ß√£o. No come√ßo, ela ficou um pouco intimidada com todas aquelas linhas de c√≥digo e com a complexidade dos comandos. Mas com determina√ß√£o e muita pr√°tica, ela foi superando os desafios e aprendendo aos poucos.\n",
      "\n",
      "Ao longo da jornada, Sofia descobriu que a programa√ß√£o exigia muito mais do que apenas habilidades t√©cnicas. Era preciso ter paci√™ncia, criatividade e uma boa dose de resili√™ncia para enfrentar os erros e bugs que surgiam pelo caminho.\n",
      "\n",
      "Com o passar do tempo, Sofia foi se aperfei√ßoando e se apaixonando cada vez mais pela programa√ß√£o. El"
     ]
    }
   ],
   "source": [
    "pergunta = 'Conte uma hist√≥ria breve sobre a jornada de aprender a programar'\n",
    "for trecho in llm.stream(pergunta):\n",
    "    print(trecho, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a80ae2cc",
   "metadata": {},
   "source": [
    "### Chamadas simult√¢neas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce4ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "O c√©u √© uma regi√£o do espa√ßo que pode ser vista a partir da superf√≠cie da Terra e que abrange todas as estrelas, planetas e outros corpos celestes vis√≠veis a olho nu. √â tamb√©m conhecido como a ab√≥bada celeste ou firmamento. O c√©u √© considerado um lugar divino em muitas religi√µes e cren√ßas, onde se acredita que as almas dos mortos v√£o ap√≥s a morte. Tamb√©m √© frequentemente associado √† ideia de paz, beleza e eternidade. No entanto, cientificamente, o c√©u √© apenas a atmosfera da Terra, composta por gases, nuvens e outros elementos que formam o clima e a meteorologia. \n",
      "\n",
      "\n",
      "A terra √© o terceiro planeta do sistema solar, localizado a uma dist√¢ncia m√©dia de 149,6 milh√µes de quil√¥metros do sol. √â o √∫nico planeta conhecido at√© o momento que possui condi√ß√µes favor√°veis para a exist√™ncia de vida, devido √† sua atmosfera, √°gua l√≠quida em sua superf√≠cie e uma diversidade de organismos vivos. A terra √© composta por camadas geol√≥gicas, como a crosta, o manto e o n√∫cleo, e possui um di√¢metro de cerca de 12.740 quil√¥metros. Al√©m disso, √© o lar de milh√µes de esp√©cies de plantas e animais, incluindo os seres humanos, que dependem dela para sobreviver. \n",
      "\n",
      "\n",
      "As estrelas s√£o corpos celestes que emitem luz e calor pr√≥prios devido a rea√ß√µes de fus√£o nuclear em seu n√∫cleo. Elas s√£o formadas por gases e poeira c√≥smica que se agrupam e se condensam em uma esfera, devido √† for√ßa da gravidade. S√£o encontradas em grande quantidade no universo e s√£o respons√°veis por iluminar e aquecer os planetas que orbitam ao seu redor. Existem diferentes tipos de estrelas, com diferentes tamanhos, cores e temperaturas.\n"
     ]
    }
   ],
   "source": [
    "perguntas = [\n",
    "    'O que √© o c√©u?',\n",
    "    'O que √© a terra?',\n",
    "    'O que s√£o as estrelas?'\n",
    "]\n",
    "\n",
    "for resposta in llm.batch(perguntas):\n",
    "    print(resposta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f6d48b1",
   "metadata": {},
   "source": [
    "## ChatModels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8796004d",
   "metadata": {},
   "source": [
    "ChatModels s√£o um componente central do LangChain.\n",
    "\n",
    "Um modelo de chat √© um modelo de linguagem que utiliza mensagens de chat como entradas e retorna mensagens de chat como sa√≠das (ao inv√©s de usar texto puro).\n",
    "\n",
    "O LangChain possui integra√ß√µes com v√°rios provedores de modelos (OpenAI, Cohere, Hugging Face, etc.) e exp√µe uma interface padr√£o para interagir com todos esses modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e887b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c38bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content='Voc√™ √© uma professora de LLM muito simp√°tica, que explica para quem n√£o √© da √°rea.'),\n",
    "    HumanMessage(content='O que √© transformer?')\n",
    "]\n",
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "085f5b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ìtima pergunta! Vou te explicar de uma forma simples:\n",
      "\n",
      "**Transformer** √© uma arquitetura de intelig√™ncia artificial criada em 2017, muito usada para entender e gerar textos ‚Äì como eu estou fazendo agora üòä.\n",
      "\n",
      "Antes dos Transformers, os modelos antigos liam um texto palavra por palavra, na ordem certinha, o que dificultava entender rela√ß√µes de palavras que estavam longe uma da outra na frase.\n",
      "\n",
      "O Transformer tem uma ideia brilhante: ele olha para todas as palavras do texto ao mesmo tempo e tenta entender como elas se relacionam, mesmo as que est√£o distantes! Isso √© feito com uma t√©cnica chamada **aten√ß√£o** (\"attention\", em ingl√™s).\n",
      "\n",
      "**Por exemplo:**  \n",
      "Se voc√™ l√™ a frase ‚ÄúO Jo√£o foi ao parque porque ele queria brincar‚Äù, o modelo precisa entender que ‚Äúele‚Äù se refere ao ‚ÄúJo√£o‚Äù. Os Transformers s√£o muito bons nisso!\n",
      "\n",
      "**Por que ele ficou famoso?**\n",
      "- Ele permite treinar modelos enormes, como o ChatGPT e o Google Translate.\n",
      "- Consegue lidar com textos longos e complexos.\n",
      "- Funciona n√£o s√≥ com textos, mas tamb√©m com imagens, sons, etc!\n",
      "\n",
      "**Resumindo:**  \n",
      "O Transformer √© um modelo de IA que revolucionou o jeito de entender e gerar linguagem, justamente porque consegue ‚Äúprestar aten√ß√£o‚Äù ao contexto inteiro do texto, e n√£o s√≥ seguir palavra por palavra.\n",
      "\n",
      "Se voc√™ quiser saber mais sobre alguma parte ‚Äî como funciona essa tal de ‚Äúaten√ß√£o‚Äù, ou quiser exemplos pr√°ticos ‚Äî me avise!\n"
     ]
    }
   ],
   "source": [
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c7a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 303,\n",
       "  'prompt_tokens': 36,\n",
       "  'total_tokens': 339,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4.1-2025-04-14',\n",
       " 'system_fingerprint': 'fp_b38e740b47',\n",
       " 'id': 'chatcmpl-BYfAcQ6q8xHDep3xXqq6HzEonqmpU',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af00b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 √© 2‚Ä¶ Exceto quando est√£o apaixonados, a√≠ viram 1 s√≥! üòÑ"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content='Voc√™ √© um assistente que conta piadas.'),\n",
    "    HumanMessage(content='Quanto √© 1 + 1?')\n",
    "]\n",
    "for trecho in chat.stream(mensagens):\n",
    "    print(trecho.content, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efae899e",
   "metadata": {},
   "source": [
    "Existem 5 tipos diferentes de mensagens:\n",
    "\n",
    "- `HumanMessage`: Isso representa uma mensagem do usu√°rio. Geralmente consiste apenas de conte√∫do.\n",
    "\n",
    "- `AIMessage`: Isso representa uma mensagem do modelo. Pode ter additional_kwargs inclu√≠dos - por exemplo, tool_calls se estiver usando chamadas de ferramentas da OpenAI.\n",
    "\n",
    "- `SystemMessage`: Isso representa uma mensagem do sistema, que indica ao modelo como se comportar. Geralmente consiste apenas de conte√∫do. Nem todo modelo suporta isso.\n",
    "\n",
    "- `FunctionMessage`: Isso representa o resultado de uma chamada de fun√ß√£o. Al√©m do papel e conte√∫do, esta mensagem tem um par√¢metro de nome que transmite o nome da fun√ß√£o que foi chamada para produzir este resultado.\n",
    "\n",
    "- `ToolMessage`: Isso representa o resultado de uma chamada de ferramenta. Isso √© distinto de uma Mensagem de Fun√ß√£o a fim de corresponder aos tipos de mensagens de fun√ß√£o e ferramenta da OpenAI. Al√©m do papel e conte√∫do, esta mensagem tem um par√¢metro tool_call_id que transmite o id da chamada √† ferramenta que foi feita para produzir este resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efaf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
